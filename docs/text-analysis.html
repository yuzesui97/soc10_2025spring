<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Week 6 Text Analysis | Stanford Spring 2025 Intro to Computational Social Science</title>
  <meta name="description" content="Week 6 Text Analysis | Stanford Spring 2025 Intro to Computational Social Science" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Week 6 Text Analysis | Stanford Spring 2025 Intro to Computational Social Science" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Week 6 Text Analysis | Stanford Spring 2025 Intro to Computational Social Science" />
  
  
  

<meta name="author" content="Yuze Sui" />


<meta name="date" content="2025-03-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="collecting-data-online.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro_Comp_Social_Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="1" data-path="intro-to-r.html"><a href="intro-to-r.html"><i class="fa fa-check"></i><b>1</b> Intro to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro-to-r.html"><a href="intro-to-r.html#r-basics"><i class="fa fa-check"></i><b>1.1</b> R Basics</a></li>
<li class="chapter" data-level="1.2" data-path="intro-to-r.html"><a href="intro-to-r.html#vectors"><i class="fa fa-check"></i><b>1.2</b> Vectors</a></li>
<li class="chapter" data-level="1.3" data-path="intro-to-r.html"><a href="intro-to-r.html#loading-packages"><i class="fa fa-check"></i><b>1.3</b> Loading Packages</a></li>
<li class="chapter" data-level="1.4" data-path="intro-to-r.html"><a href="intro-to-r.html#exploring-and-visualizing-data"><i class="fa fa-check"></i><b>1.4</b> Exploring and Visualizing Data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html"><i class="fa fa-check"></i><b>2</b> Surveys and Survey Experiments with Qualtrics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#creating-a-qualtrics-account"><i class="fa fa-check"></i><b>2.2</b> Creating a Qualtrics account</a></li>
<li class="chapter" data-level="2.3" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#survey-options"><i class="fa fa-check"></i><b>2.3</b> Survey options</a></li>
<li class="chapter" data-level="2.4" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#a-quick-survey-experiment"><i class="fa fa-check"></i><b>2.4</b> A quick survey experiment</a></li>
<li class="chapter" data-level="2.5" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#publish-it"><i class="fa fa-check"></i><b>2.5</b> Publish it!</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression-and-classification.html"><a href="regression-and-classification.html"><i class="fa fa-check"></i><b>3</b> Regression and Classification</a>
<ul>
<li class="chapter" data-level="3.1" data-path="regression-and-classification.html"><a href="regression-and-classification.html#linear-regression"><i class="fa fa-check"></i><b>3.1</b> Linear Regression</a></li>
<li class="chapter" data-level="3.2" data-path="regression-and-classification.html"><a href="regression-and-classification.html#how-linear-regression-works"><i class="fa fa-check"></i><b>3.2</b> How linear regression works</a></li>
<li class="chapter" data-level="3.3" data-path="regression-and-classification.html"><a href="regression-and-classification.html#linear-regression-using-the-lm-function"><i class="fa fa-check"></i><b>3.3</b> Linear regression using the lm function</a></li>
<li class="chapter" data-level="3.4" data-path="regression-and-classification.html"><a href="regression-and-classification.html#multiple-regression"><i class="fa fa-check"></i><b>3.4</b> Multiple Regression</a></li>
<li class="chapter" data-level="3.5" data-path="regression-and-classification.html"><a href="regression-and-classification.html#linear-regression-prediction"><i class="fa fa-check"></i><b>3.5</b> Linear Regression Prediction</a></li>
<li class="chapter" data-level="3.6" data-path="regression-and-classification.html"><a href="regression-and-classification.html#classification-logistic-regression"><i class="fa fa-check"></i><b>3.6</b> Classification (Logistic Regression)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="social-network-analysis.html"><a href="social-network-analysis.html"><i class="fa fa-check"></i><b>4</b> Social Network Analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#understanding-network-data-structures-in-r"><i class="fa fa-check"></i><b>4.1</b> Understanding network data structures in R</a></li>
<li class="chapter" data-level="4.2" data-path="social-network-analysis.html"><a href="social-network-analysis.html#visualizing-network-data-in-r"><i class="fa fa-check"></i><b>4.2</b> Visualizing network data in R</a></li>
<li class="chapter" data-level="4.3" data-path="social-network-analysis.html"><a href="social-network-analysis.html#key-network-measures"><i class="fa fa-check"></i><b>4.3</b> Key network measures</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#degree-how-many-friends-do-i-have"><i class="fa fa-check"></i><b>4.3.1</b> Degree (“How many friends do I have?”)</a></li>
<li class="chapter" data-level="4.3.2" data-path="social-network-analysis.html"><a href="social-network-analysis.html#weighted-degree-strength"><i class="fa fa-check"></i><b>4.3.2</b> Weighted degree (strength)</a></li>
<li class="chapter" data-level="4.3.3" data-path="social-network-analysis.html"><a href="social-network-analysis.html#global-clustering-coefficient-gcc"><i class="fa fa-check"></i><b>4.3.3</b> Global Clustering Coefficient (GCC)</a></li>
<li class="chapter" data-level="4.3.4" data-path="social-network-analysis.html"><a href="social-network-analysis.html#average-path-length-apl"><i class="fa fa-check"></i><b>4.3.4</b> Average path length (APL)</a></li>
<li class="chapter" data-level="4.3.5" data-path="social-network-analysis.html"><a href="social-network-analysis.html#assortativity"><i class="fa fa-check"></i><b>4.3.5</b> Assortativity</a></li>
<li class="chapter" data-level="4.3.6" data-path="social-network-analysis.html"><a href="social-network-analysis.html#betweenness-centrality"><i class="fa fa-check"></i><b>4.3.6</b> Betweenness centrality</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="social-network-analysis.html"><a href="social-network-analysis.html#visualizing-key-measures"><i class="fa fa-check"></i><b>4.4</b> Visualizing Key Measures</a></li>
<li class="chapter" data-level="4.5" data-path="social-network-analysis.html"><a href="social-network-analysis.html#benchmark-our-empirical-network"><i class="fa fa-check"></i><b>4.5</b> Benchmark our empirical network</a></li>
<li class="chapter" data-level="4.6" data-path="social-network-analysis.html"><a href="social-network-analysis.html#find-local-clusterscommunities"><i class="fa fa-check"></i><b>4.6</b> Find local clusters/communities</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#other-resources"><i class="fa fa-check"></i><b>4.6.1</b> Other Resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="collecting-data-online.html"><a href="collecting-data-online.html"><i class="fa fa-check"></i><b>5</b> Collecting Data Online</a>
<ul>
<li class="chapter" data-level="5.1" data-path="collecting-data-online.html"><a href="collecting-data-online.html#scraping-the-web"><i class="fa fa-check"></i><b>5.1</b> Scraping the web</a></li>
<li class="chapter" data-level="5.2" data-path="collecting-data-online.html"><a href="collecting-data-online.html#google-news-api"><i class="fa fa-check"></i><b>5.2</b> Google News API</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="collecting-data-online.html"><a href="collecting-data-online.html#prerequistes"><i class="fa fa-check"></i><b>5.2.1</b> Prerequistes</a></li>
<li class="chapter" data-level="5.2.2" data-path="collecting-data-online.html"><a href="collecting-data-online.html#get-started"><i class="fa fa-check"></i><b>5.2.2</b> Get started</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="text-analysis.html"><a href="text-analysis.html"><i class="fa fa-check"></i><b>6</b> Text Analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="text-analysis.html"><a href="text-analysis.html#sentiment-analysis"><i class="fa fa-check"></i><b>6.1</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="6.2" data-path="text-analysis.html"><a href="text-analysis.html#topic-modeling"><i class="fa fa-check"></i><b>6.2</b> Topic Modeling</a></li>
<li class="chapter" data-level="6.3" data-path="text-analysis.html"><a href="text-analysis.html#word-embeddings"><i class="fa fa-check"></i><b>6.3</b> Word Embeddings</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stanford Spring 2025 Intro to Computational Social Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="text-analysis" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Week 6</span> Text Analysis<a href="text-analysis.html#text-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>This section is inspired by <a href="https://m-clark.github.io/text-analysis-with-R/sentiment-analysis.html" class="uri">https://m-clark.github.io/text-analysis-with-R/sentiment-analysis.html</a>.</em></p>
<p>Text data are now everywhere: tweets and forum posts, press releases and policy documents, interview transcripts and open-ended survey answers. Turning that unstructured torrent into systematic evidence is quickly becoming a core skill for social scientists, data analysts, and anyone who needs to understand language at scale.</p>
<p>This hands-on R tutorial walks you through three foundational techniques—sentiment analysis, topic modeling, and word embeddings—that together cover the full spectrum from simple lexicon-based scoring to advanced distributional semantics.</p>
<div id="sentiment-analysis" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Sentiment Analysis<a href="text-analysis.html#sentiment-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sentiment analysis is often the most intuitive entry point to text analytics. Its goal is to quantify the emotional tone of a corpus. Although a human reader can judge sentiment in a single sentence, automated methods are indispensable when the dataset grows to hundreds of thousands or even millions of sentences and documents.</p>
<p>The tidytext package in R streamlines this process. Let’s start by installing this pacakge.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="text-analysis.html#cb131-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;tidytext&quot;</span>)</span>
<span id="cb131-2"><a href="text-analysis.html#cb131-2" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span></code></pre></div>
<p>A common tidy-text sentiment method treats a document’s sentiment as the sum of the sentiments of its individual words. We can use existing lexicons to map individual words with sentiment.</p>
<p>Lexicons available in tidytext:
AFINN – assigns each word an integer score from –5 (very negative) to +5 (very positive).
bing – labels words simply as positive or negative.
nrc – labels words as positive or negative and in eight basic emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust).</p>
<p>All three lexicons are unigram-based and cover thousands of English words, making them general-purpose tools for quick sentiment tagging within the tidy ecosystem.</p>
<p>Let’s take a look at the “bing” lexicon.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="text-analysis.html#cb132-1" tabindex="-1"></a><span class="fu">get_sentiments</span>(<span class="st">&quot;bing&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="text-analysis.html#cb133-1" tabindex="-1"></a><span class="co"># A tibble: 6,786 × 2</span></span>
<span id="cb133-2"><a href="text-analysis.html#cb133-2" tabindex="-1"></a>   word        sentiment</span>
<span id="cb133-3"><a href="text-analysis.html#cb133-3" tabindex="-1"></a>   <span class="sc">&lt;</span>chr<span class="sc">&gt;</span>       <span class="er">&lt;</span>chr<span class="sc">&gt;</span>    </span>
<span id="cb133-4"><a href="text-analysis.html#cb133-4" tabindex="-1"></a> <span class="dv">1</span> <span class="dv">2</span><span class="sc">-</span>faces     negative </span>
<span id="cb133-5"><a href="text-analysis.html#cb133-5" tabindex="-1"></a> <span class="dv">2</span> abnormal    negative </span>
<span id="cb133-6"><a href="text-analysis.html#cb133-6" tabindex="-1"></a> <span class="dv">3</span> abolish     negative </span>
<span id="cb133-7"><a href="text-analysis.html#cb133-7" tabindex="-1"></a> <span class="dv">4</span> abominable  negative </span>
<span id="cb133-8"><a href="text-analysis.html#cb133-8" tabindex="-1"></a> <span class="dv">5</span> abominably  negative </span>
<span id="cb133-9"><a href="text-analysis.html#cb133-9" tabindex="-1"></a> <span class="dv">6</span> abominate   negative </span>
<span id="cb133-10"><a href="text-analysis.html#cb133-10" tabindex="-1"></a> <span class="dv">7</span> abomination negative </span>
<span id="cb133-11"><a href="text-analysis.html#cb133-11" tabindex="-1"></a> <span class="dv">8</span> abort       negative </span>
<span id="cb133-12"><a href="text-analysis.html#cb133-12" tabindex="-1"></a> <span class="dv">9</span> aborted     negative </span>
<span id="cb133-13"><a href="text-analysis.html#cb133-13" tabindex="-1"></a><span class="dv">10</span> aborts      negative </span>
<span id="cb133-14"><a href="text-analysis.html#cb133-14" tabindex="-1"></a><span class="co"># ℹ 6,776 more rows</span></span>
<span id="cb133-15"><a href="text-analysis.html#cb133-15" tabindex="-1"></a><span class="co"># ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
<p>Let’s store the “bing” lexicon into a dataframe and use it to assess the sentiment of the novel “The Wonderful Wizard of Oz”.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="text-analysis.html#cb134-1" tabindex="-1"></a>bing_sent <span class="ot">&lt;-</span> <span class="fu">get_sentiments</span>(<span class="st">&quot;bing&quot;</span>)</span></code></pre></div>
<p>Lexicon gives us a dictionary/reference to label the sentiments of the words that are under evaluation. But how exactly should we conduct sentiment analysis for a text? Below visualizes the workflow of conducting sentiment analysis using tidytext <a href="https://www.tidytextmining.com/sentiment">Figure Source</a>.</p>
<p><img src="week6_plot1.png" /></p>
<p>Let’s start by importing the text of the novel “The Wonderful Wizard of Oz”. We can access the text via the Project Gutenberg (<a href="https://www.gutenberg.org" class="uri">https://www.gutenberg.org</a>), a library of over 75,000 free eBooks. Let’s install the R packakge for Project Gutenberg and retrieve the text of the novel “The Wonderful Wizard of Oz”.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="text-analysis.html#cb135-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;gutenbergr&quot;</span>)</span>
<span id="cb135-2"><a href="text-analysis.html#cb135-2" tabindex="-1"></a><span class="fu">library</span>(gutenbergr)</span>
<span id="cb135-3"><a href="text-analysis.html#cb135-3" tabindex="-1"></a>book_oz <span class="ot">=</span> <span class="fu">gutenberg_works</span>(title <span class="sc">==</span> <span class="st">&quot;The Wonderful Wizard of Oz&quot;</span>)  </span></code></pre></div>
<p>Let’s take a look of the book_oz object we just created.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="text-analysis.html#cb136-1" tabindex="-1"></a>book_oz</span></code></pre></div>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="text-analysis.html#cb137-1" tabindex="-1"></a><span class="co"># A tibble: 1 × 8</span></span>
<span id="cb137-2"><a href="text-analysis.html#cb137-2" tabindex="-1"></a>  gutenberg_id title                author gutenberg_author_id language gutenberg_bookshelf rights has_text</span>
<span id="cb137-3"><a href="text-analysis.html#cb137-3" tabindex="-1"></a>         <span class="sc">&lt;</span>int<span class="sc">&gt;</span> <span class="er">&lt;</span>chr<span class="sc">&gt;</span>                <span class="er">&lt;</span>chr<span class="sc">&gt;</span>                <span class="er">&lt;</span>int<span class="sc">&gt;</span> <span class="er">&lt;</span>chr<span class="sc">&gt;</span>    <span class="er">&lt;</span>chr<span class="sc">&gt;</span>               <span class="er">&lt;</span>chr<span class="sc">&gt;</span>  <span class="er">&lt;</span>lgl<span class="sc">&gt;</span>   </span>
<span id="cb137-4"><a href="text-analysis.html#cb137-4" tabindex="-1"></a><span class="dv">1</span>        <span class="dv">43936</span> The Wonderful Wizar… Baum,…                  <span class="dv">42</span> en       <span class="st">&quot;&quot;</span>                  Publi… <span class="cn">TRUE</span>    </span></code></pre></div>
<p>We can donwload the text by going to the website and using our gutenberg_id.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="text-analysis.html#cb138-1" tabindex="-1"></a>text_oz <span class="ot">=</span> <span class="fu">gutenberg_download</span>(book_oz<span class="sc">$</span>gutenberg_id)</span></code></pre></div>
<p>Let’s take a look at text_oz and notice that there are still things to be cleaned. We first slice off the initial parts we don’t want like title, author etc. Then we get rid of other tidbits that would interfere, using a little regex as well to aid the process.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="text-analysis.html#cb139-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb139-2"><a href="text-analysis.html#cb139-2" tabindex="-1"></a>text_oz_filtered <span class="ot">=</span> text_oz <span class="sc">%&gt;%</span> </span>
<span id="cb139-3"><a href="text-analysis.html#cb139-3" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)) <span class="sc">%&gt;%</span>  <span class="co">#Drops the first 20 rows (negative slice = “all but”). These rows are usually Gutenberg boiler-plate (title page, licensing notes, table of contents). </span></span>
<span id="cb139-4"><a href="text-analysis.html#cb139-4" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>text<span class="sc">==</span><span class="fu">str_to_upper</span>(text),            <span class="co"># Eliminates rows whose entire string is in ALL-CAPS. In a Shakespeare script those are mostly block headers—THE PROLOGUE, ENTER HORATIO, etc.—which carry no narrative sentiment.</span></span>
<span id="cb139-5"><a href="text-analysis.html#cb139-5" tabindex="-1"></a>         <span class="sc">!</span>text<span class="sc">==</span><span class="fu">str_to_title</span>(text),            <span class="co"># Eliminates rows whose string equals its Title-Case version. </span></span>
<span id="cb139-6"><a href="text-analysis.html#cb139-6" tabindex="-1"></a>         <span class="sc">!</span><span class="fu">str_detect</span>(text, <span class="at">pattern=</span><span class="st">&#39;^(Scene|SCENE)|^(Act|ACT)|^</span><span class="sc">\\</span><span class="st">[&#39;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb139-7"><a href="text-analysis.html#cb139-7" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>gutenberg_id) <span class="sc">%&gt;%</span>  <span class="co">#Drops the unneeded gutenberg_id column to declutter the data frame.</span></span>
<span id="cb139-8"><a href="text-analysis.html#cb139-8" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(sentence, <span class="at">input=</span>text, <span class="at">token=</span><span class="st">&#39;sentences&#39;</span>) <span class="sc">%&gt;%</span>  <span class="co">#Splits each surviving line into individual sentences (tidytext tokenization), giving one row per sentence—ideal granularity for sentiment scoring.</span></span>
<span id="cb139-9"><a href="text-analysis.html#cb139-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sentenceID =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">n</span>()) <span class="co">#Adds a running sentenceID so every sentence has a unique key for joins, plotting, or ordering later on.</span></span></code></pre></div>
<p>In addition, we can remove stopwords like a, an, the etc., and tidytext comes with a stop_words data frame.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="text-analysis.html#cb140-1" tabindex="-1"></a><span class="fu">head</span>(stop_words<span class="sc">$</span>word)</span></code></pre></div>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="text-analysis.html#cb141-1" tabindex="-1"></a><span class="st">&quot;a&quot;</span>         <span class="st">&quot;a&#39;s&quot;</span>       <span class="st">&quot;able&quot;</span>      <span class="st">&quot;about&quot;</span>     <span class="st">&quot;above&quot;</span>     <span class="st">&quot;according&quot;</span></span></code></pre></div>
<p>Let’s now parse the sentence-level document into words and remove stop_words using anti_join.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="text-analysis.html#cb142-1" tabindex="-1"></a>text_oz_filtered <span class="ot">=</span> text_oz_filtered <span class="sc">%&gt;%</span> </span>
<span id="cb142-2"><a href="text-analysis.html#cb142-2" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(<span class="at">output=</span>word, <span class="at">input=</span>sentence, <span class="at">token=</span><span class="st">&#39;words&#39;</span>) <span class="sc">%&gt;%</span>   </span>
<span id="cb142-3"><a href="text-analysis.html#cb142-3" tabindex="-1"></a>  <span class="fu">anti_join</span>(stop_words)</span></code></pre></div>
<p>Let’s take a look at the the most frequent words appeared in the novel.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="text-analysis.html#cb143-1" tabindex="-1"></a>text_oz_filtered <span class="sc">%&gt;%</span> </span>
<span id="cb143-2"><a href="text-analysis.html#cb143-2" tabindex="-1"></a>  <span class="fu">count</span>(word) <span class="sc">%&gt;%</span> </span>
<span id="cb143-3"><a href="text-analysis.html#cb143-3" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(n))</span></code></pre></div>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="text-analysis.html#cb144-1" tabindex="-1"></a><span class="co"># A tibble: 2,508 × 2</span></span>
<span id="cb144-2"><a href="text-analysis.html#cb144-2" tabindex="-1"></a>   word          n</span>
<span id="cb144-3"><a href="text-analysis.html#cb144-3" tabindex="-1"></a>   <span class="sc">&lt;</span>chr<span class="sc">&gt;</span>     <span class="er">&lt;</span>int<span class="sc">&gt;</span></span>
<span id="cb144-4"><a href="text-analysis.html#cb144-4" tabindex="-1"></a> <span class="dv">1</span> dorothy     <span class="dv">343</span></span>
<span id="cb144-5"><a href="text-analysis.html#cb144-5" tabindex="-1"></a> <span class="dv">2</span> scarecrow   <span class="dv">215</span></span>
<span id="cb144-6"><a href="text-analysis.html#cb144-6" tabindex="-1"></a> <span class="dv">3</span> woodman     <span class="dv">172</span></span>
<span id="cb144-7"><a href="text-analysis.html#cb144-7" tabindex="-1"></a> <span class="dv">4</span> lion        <span class="dv">171</span></span>
<span id="cb144-8"><a href="text-analysis.html#cb144-8" tabindex="-1"></a> <span class="dv">5</span> oz          <span class="dv">161</span></span>
<span id="cb144-9"><a href="text-analysis.html#cb144-9" tabindex="-1"></a> <span class="dv">6</span> tin         <span class="dv">139</span></span>
<span id="cb144-10"><a href="text-analysis.html#cb144-10" tabindex="-1"></a> <span class="dv">7</span> witch       <span class="dv">123</span></span>
<span id="cb144-11"><a href="text-analysis.html#cb144-11" tabindex="-1"></a> <span class="dv">8</span> green       <span class="dv">105</span></span>
<span id="cb144-12"><a href="text-analysis.html#cb144-12" tabindex="-1"></a> <span class="dv">9</span> girl         <span class="dv">93</span></span>
<span id="cb144-13"><a href="text-analysis.html#cb144-13" tabindex="-1"></a><span class="dv">10</span> head         <span class="dv">90</span></span>
<span id="cb144-14"><a href="text-analysis.html#cb144-14" tabindex="-1"></a><span class="co"># ℹ 2,498 more rows</span></span>
<span id="cb144-15"><a href="text-analysis.html#cb144-15" tabindex="-1"></a><span class="co"># ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
<p>We can then merge the word-level data with our Bing lexicon to map words with sentiments.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="text-analysis.html#cb145-1" tabindex="-1"></a>oz_sentiment <span class="ot">=</span> text_oz_filtered <span class="sc">%&gt;%</span> </span>
<span id="cb145-2"><a href="text-analysis.html#cb145-2" tabindex="-1"></a>  <span class="fu">inner_join</span>(bing_sent)</span></code></pre></div>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="text-analysis.html#cb146-1" tabindex="-1"></a>oz_sentiment</span></code></pre></div>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="text-analysis.html#cb147-1" tabindex="-1"></a><span class="co"># A tibble: 1,943 × 3</span></span>
<span id="cb147-2"><a href="text-analysis.html#cb147-2" tabindex="-1"></a>   sentenceID word      sentiment</span>
<span id="cb147-3"><a href="text-analysis.html#cb147-3" tabindex="-1"></a>        <span class="sc">&lt;</span>int<span class="sc">&gt;</span> <span class="er">&lt;</span>chr<span class="sc">&gt;</span>     <span class="er">&lt;</span>chr<span class="sc">&gt;</span>    </span>
<span id="cb147-4"><a href="text-analysis.html#cb147-4" tabindex="-1"></a> <span class="dv">1</span>          <span class="dv">2</span> healthy   positive </span>
<span id="cb147-5"><a href="text-analysis.html#cb147-5" tabindex="-1"></a> <span class="dv">2</span>          <span class="dv">2</span> wholesome positive </span>
<span id="cb147-6"><a href="text-analysis.html#cb147-6" tabindex="-1"></a> <span class="dv">3</span>          <span class="dv">3</span> love      positive </span>
<span id="cb147-7"><a href="text-analysis.html#cb147-7" tabindex="-1"></a> <span class="dv">4</span>          <span class="dv">3</span> fantastic positive </span>
<span id="cb147-8"><a href="text-analysis.html#cb147-8" tabindex="-1"></a> <span class="dv">5</span>          <span class="dv">3</span> marvelous positive </span>
<span id="cb147-9"><a href="text-analysis.html#cb147-9" tabindex="-1"></a> <span class="dv">6</span>          <span class="dv">4</span> unreal    positive </span>
<span id="cb147-10"><a href="text-analysis.html#cb147-10" tabindex="-1"></a> <span class="dv">7</span>          <span class="dv">6</span> happiness positive </span>
<span id="cb147-11"><a href="text-analysis.html#cb147-11" tabindex="-1"></a> <span class="dv">8</span>          <span class="dv">6</span> childish  negative </span>
<span id="cb147-12"><a href="text-analysis.html#cb147-12" tabindex="-1"></a> <span class="dv">9</span>         <span class="dv">11</span> horrible  negative </span>
<span id="cb147-13"><a href="text-analysis.html#cb147-13" tabindex="-1"></a><span class="dv">10</span>         <span class="dv">12</span> fearsome  negative </span>
<span id="cb147-14"><a href="text-analysis.html#cb147-14" tabindex="-1"></a><span class="co"># ℹ 1,933 more rows</span></span>
<span id="cb147-15"><a href="text-analysis.html#cb147-15" tabindex="-1"></a><span class="co"># ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
<p>We can now aggregate the sentiments to the sentence level. Let’s count positive vs. negative words in each sentence since we assign binary sentiments to words.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="text-analysis.html#cb148-1" tabindex="-1"></a>sentiment_counts <span class="ot">&lt;-</span> oz_sentiment <span class="sc">%&gt;%</span>               </span>
<span id="cb148-2"><a href="text-analysis.html#cb148-2" tabindex="-1"></a>  <span class="fu">count</span>(sentenceID, sentiment) <span class="sc">%&gt;%</span>                  <span class="co"># number of words by sentiment per sentence</span></span>
<span id="cb148-3"><a href="text-analysis.html#cb148-3" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from  =</span> sentiment,              <span class="co"># … → wide form: one row per sentence</span></span>
<span id="cb148-4"><a href="text-analysis.html#cb148-4" tabindex="-1"></a>              <span class="at">values_from =</span> n,</span>
<span id="cb148-5"><a href="text-analysis.html#cb148-5" tabindex="-1"></a>              <span class="at">values_fill =</span> <span class="dv">0</span>)                      <span class="co"># sentences w/ no pos/neg get 0</span></span></code></pre></div>
<p>Let’s get an assessment on the sentence-level sentiment by taking the difference between the count of positive words and the count of negative words.</p>
<pre><code>sentiment_counts$diff &lt;- sentiment_counts$positive - sentiment_counts$negative</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="text-analysis.html#cb150-1" tabindex="-1"></a><span class="fu">ggplot</span>(sentiment_counts,</span>
<span id="cb150-2"><a href="text-analysis.html#cb150-2" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> sentenceID, <span class="at">y =</span> diff)) <span class="sc">+</span></span>
<span id="cb150-3"><a href="text-analysis.html#cb150-3" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb150-4"><a href="text-analysis.html#cb150-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Sentence-level Sentiment in *The Wonderful Wizard of Oz*&quot;</span>,</span>
<span id="cb150-5"><a href="text-analysis.html#cb150-5" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Sentence order in text&quot;</span>,</span>
<span id="cb150-6"><a href="text-analysis.html#cb150-6" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Sentence-level Sentiment&quot;</span>) </span></code></pre></div>
<p><img src="week6_plot2.png" /></p>
<p>Let’s smooth the plot a bit by grouping every 50 sentences together.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="text-analysis.html#cb151-1" tabindex="-1"></a>sentiment_counts <span class="sc">%&gt;%</span></span>
<span id="cb151-2"><a href="text-analysis.html#cb151-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">window =</span> sentenceID <span class="sc">%/%</span> <span class="dv">50</span>) <span class="sc">%&gt;%</span>          <span class="co"># 50-sentence blocks</span></span>
<span id="cb151-3"><a href="text-analysis.html#cb151-3" tabindex="-1"></a>  <span class="fu">group_by</span>(window) <span class="sc">%&gt;%</span></span>
<span id="cb151-4"><a href="text-analysis.html#cb151-4" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">diff =</span> <span class="fu">sum</span>(positive) <span class="sc">-</span> <span class="fu">sum</span>(negative)) <span class="sc">%&gt;%</span></span>
<span id="cb151-5"><a href="text-analysis.html#cb151-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(window, diff)) <span class="sc">+</span> <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="week6_plot3.png" /></p>
</div>
<div id="topic-modeling" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Topic Modeling<a href="text-analysis.html#topic-modeling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Topic modeling is an unsupervised machine-learning technique that scans a collection of documents and groups words that frequently appear together into latent “topics.” Each topic represents a coherent theme—such as “injury reports,” “transfer rumors,” or “playoff predictions”—and every article is scored on how strongly it exhibits each theme.</p>
<p>In this tutorial, I will run a topic model on the latest 100 sports-news articles pulled via a News API. It would quantify how much attention different sports, teams, or issues are receiving. In short, it turns a raw stream of headlines into a structured map of the current sports-news agenda.</p>
<p>Let’s go back to the News API to retrieve the latest 100 articles from ESPN.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="text-analysis.html#cb152-1" tabindex="-1"></a><span class="fu">library</span>(httr)        <span class="co"># talk to web APIs</span></span>
<span id="cb152-2"><a href="text-analysis.html#cb152-2" tabindex="-1"></a><span class="fu">library</span>(jsonlite)    <span class="co"># parse JSON responses</span></span>
<span id="cb152-3"><a href="text-analysis.html#cb152-3" tabindex="-1"></a></span>
<span id="cb152-4"><a href="text-analysis.html#cb152-4" tabindex="-1"></a>endpoint_url <span class="ot">&lt;-</span> <span class="st">&quot;https://newsapi.org/v2/everything&quot;</span></span>
<span id="cb152-5"><a href="text-analysis.html#cb152-5" tabindex="-1"></a></span>
<span id="cb152-6"><a href="text-analysis.html#cb152-6" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">NEWS_API_KEY =</span> <span class="st">&quot;insert your api here&quot;</span>)   </span>
<span id="cb152-7"><a href="text-analysis.html#cb152-7" tabindex="-1"></a>my_api_key <span class="ot">&lt;-</span> <span class="fu">Sys.getenv</span>(<span class="st">&quot;NEWS_API_KEY&quot;</span>)</span>
<span id="cb152-8"><a href="text-analysis.html#cb152-8" tabindex="-1"></a></span>
<span id="cb152-9"><a href="text-analysis.html#cb152-9" tabindex="-1"></a>params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb152-10"><a href="text-analysis.html#cb152-10" tabindex="-1"></a>  <span class="at">domains   =</span> <span class="st">&quot;espn.com&quot;</span>,        <span class="co"># only ESPN</span></span>
<span id="cb152-11"><a href="text-analysis.html#cb152-11" tabindex="-1"></a>  <span class="at">language  =</span> <span class="st">&quot;en&quot;</span>,</span>
<span id="cb152-12"><a href="text-analysis.html#cb152-12" tabindex="-1"></a>  <span class="at">pageSize  =</span> <span class="dv">100</span>,               <span class="co"># max per call</span></span>
<span id="cb152-13"><a href="text-analysis.html#cb152-13" tabindex="-1"></a>  <span class="at">sortBy    =</span> <span class="st">&quot;publishedAt&quot;</span></span>
<span id="cb152-14"><a href="text-analysis.html#cb152-14" tabindex="-1"></a>)</span>
<span id="cb152-15"><a href="text-analysis.html#cb152-15" tabindex="-1"></a></span>
<span id="cb152-16"><a href="text-analysis.html#cb152-16" tabindex="-1"></a>resp <span class="ot">&lt;-</span> <span class="fu">GET</span>(</span>
<span id="cb152-17"><a href="text-analysis.html#cb152-17" tabindex="-1"></a>  <span class="at">url   =</span> endpoint_url,</span>
<span id="cb152-18"><a href="text-analysis.html#cb152-18" tabindex="-1"></a>  <span class="at">query =</span> params,</span>
<span id="cb152-19"><a href="text-analysis.html#cb152-19" tabindex="-1"></a>  <span class="fu">add_headers</span>(<span class="at">Authorization =</span> my_api_key)</span>
<span id="cb152-20"><a href="text-analysis.html#cb152-20" tabindex="-1"></a>)</span>
<span id="cb152-21"><a href="text-analysis.html#cb152-21" tabindex="-1"></a></span>
<span id="cb152-22"><a href="text-analysis.html#cb152-22" tabindex="-1"></a><span class="do">## Parse JSON → tibble with title + description</span></span>
<span id="cb152-23"><a href="text-analysis.html#cb152-23" tabindex="-1"></a>articles_df <span class="ot">&lt;-</span> <span class="fu">content</span>(resp, <span class="at">as =</span> <span class="st">&quot;text&quot;</span>, <span class="at">encoding =</span> <span class="st">&quot;UTF-8&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb152-24"><a href="text-analysis.html#cb152-24" tabindex="-1"></a>  <span class="fu">fromJSON</span>(<span class="at">flatten =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb152-25"><a href="text-analysis.html#cb152-25" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;articles&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb152-26"><a href="text-analysis.html#cb152-26" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb152-27"><a href="text-analysis.html#cb152-27" tabindex="-1"></a>  <span class="fu">select</span>(title, description)                      <span class="co"># keep only what we need</span></span></code></pre></div>
<p>Let’s take a look at articles_df</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="text-analysis.html#cb153-1" tabindex="-1"></a><span class="fu">head</span>(articles_df)</span></code></pre></div>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="text-analysis.html#cb154-1" tabindex="-1"></a><span class="co"># A tibble: 6 × 2</span></span>
<span id="cb154-2"><a href="text-analysis.html#cb154-2" tabindex="-1"></a>  title                                                        description     </span>
<span id="cb154-3"><a href="text-analysis.html#cb154-3" tabindex="-1"></a>  <span class="sc">&lt;</span>chr<span class="sc">&gt;</span>                                                        <span class="er">&lt;</span>chr<span class="sc">&gt;</span>           </span>
<span id="cb154-4"><a href="text-analysis.html#cb154-4" tabindex="-1"></a><span class="dv">1</span> Hamilton Miami radio drama borne from Ferrari<span class="st">&#39;s lack of pace &quot;Lewis Hamilton…</span></span>
<span id="cb154-5"><a href="text-analysis.html#cb154-5" tabindex="-1"></a><span class="st">2 Reds rookie Callihan injures arm on sliding catch            &quot;With two outs …</span></span>
<span id="cb154-6"><a href="text-analysis.html#cb154-6" tabindex="-1"></a><span class="st">3 Dodgers&#39;</span> Teoscar Hernández (hamstring) exits                 <span class="st">&quot;Dodgers outfie…</span></span>
<span id="cb154-7"><a href="text-analysis.html#cb154-7" tabindex="-1"></a><span class="st">4 Mets&#39; Winker out 6-8 weeks, Minter&#39;s season over             &quot;</span>New York Mets …</span>
<span id="cb154-8"><a href="text-analysis.html#cb154-8" tabindex="-1"></a><span class="dv">5</span> Man takes <span class="dv">1</span>st steps after <span class="dv">21</span><span class="sc">-</span>foot fall at PNC Park           <span class="st">&quot;The 20-year-ol…</span></span>
<span id="cb154-9"><a href="text-analysis.html#cb154-9" tabindex="-1"></a><span class="st">6 Follow live: Braves working on no-hitter vs. Reds            &quot;</span>Live coverage …</span></code></pre></div>
<p>Let’s further clean the corpus</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="text-analysis.html#cb155-1" tabindex="-1"></a>corpus <span class="ot">&lt;-</span> articles_df <span class="sc">%&gt;%</span></span>
<span id="cb155-2"><a href="text-analysis.html#cb155-2" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(description)) <span class="sc">%&gt;%</span>                 <span class="co"># drop blanks</span></span>
<span id="cb155-3"><a href="text-analysis.html#cb155-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">doc_id =</span> <span class="fu">row_number</span>())</span>
<span id="cb155-4"><a href="text-analysis.html#cb155-4" tabindex="-1"></a></span>
<span id="cb155-5"><a href="text-analysis.html#cb155-5" tabindex="-1"></a>tokens <span class="ot">&lt;-</span> corpus <span class="sc">%&gt;%</span></span>
<span id="cb155-6"><a href="text-analysis.html#cb155-6" tabindex="-1"></a>  <span class="fu">unnest_tokens</span>(word, description) <span class="sc">%&gt;%</span>            <span class="co"># one row = one word</span></span>
<span id="cb155-7"><a href="text-analysis.html#cb155-7" tabindex="-1"></a>  <span class="fu">anti_join</span>(stop_words, <span class="at">by =</span> <span class="st">&quot;word&quot;</span>) <span class="sc">%&gt;%</span>          <span class="co"># remove stop-words</span></span>
<span id="cb155-8"><a href="text-analysis.html#cb155-8" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(word, <span class="st">&quot;[a-z]&quot;</span>))               <span class="co"># drop numbers etc.</span></span></code></pre></div>
<p>Let’s create a Document-Term Matrix (articles × words).</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="text-analysis.html#cb156-1" tabindex="-1"></a><span class="fu">library</span>(tm)</span>
<span id="cb156-2"><a href="text-analysis.html#cb156-2" tabindex="-1"></a>dtm <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb156-3"><a href="text-analysis.html#cb156-3" tabindex="-1"></a>  <span class="fu">count</span>(doc_id, word) <span class="sc">%&gt;%</span></span>
<span id="cb156-4"><a href="text-analysis.html#cb156-4" tabindex="-1"></a>  <span class="fu">cast_dtm</span>(<span class="at">document =</span> doc_id,</span>
<span id="cb156-5"><a href="text-analysis.html#cb156-5" tabindex="-1"></a>           <span class="at">term      =</span> word,</span>
<span id="cb156-6"><a href="text-analysis.html#cb156-6" tabindex="-1"></a>           <span class="at">value     =</span> n)</span></code></pre></div>
<p>Let’s fit a topic model with 5 topics!</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="text-analysis.html#cb157-1" tabindex="-1"></a><span class="fu">library</span>(topicmodels)</span>
<span id="cb157-2"><a href="text-analysis.html#cb157-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb157-3"><a href="text-analysis.html#cb157-3" tabindex="-1"></a>k         <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb157-4"><a href="text-analysis.html#cb157-4" tabindex="-1"></a>lda_model <span class="ot">&lt;-</span> <span class="fu">LDA</span>(dtm, <span class="at">k =</span> k, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">seed =</span> <span class="dv">42</span>))</span></code></pre></div>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="text-analysis.html#cb158-1" tabindex="-1"></a>top_terms <span class="ot">&lt;-</span> <span class="fu">tidy</span>(lda_model, <span class="at">matrix =</span> <span class="st">&quot;beta&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb158-2"><a href="text-analysis.html#cb158-2" tabindex="-1"></a>  <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span></span>
<span id="cb158-3"><a href="text-analysis.html#cb158-3" tabindex="-1"></a>  <span class="fu">slice_max</span>(beta, <span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span>      <span class="co"># 10 “strongest” words</span></span>
<span id="cb158-4"><a href="text-analysis.html#cb158-4" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb158-5"><a href="text-analysis.html#cb158-5" tabindex="-1"></a>  <span class="fu">arrange</span>(topic, <span class="sc">-</span>beta)</span></code></pre></div>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="text-analysis.html#cb159-1" tabindex="-1"></a>top_terms</span></code></pre></div>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="text-analysis.html#cb160-1" tabindex="-1"></a><span class="co"># A tibble: 104 × 3</span></span>
<span id="cb160-2"><a href="text-analysis.html#cb160-2" tabindex="-1"></a>   topic term      beta</span>
<span id="cb160-3"><a href="text-analysis.html#cb160-3" tabindex="-1"></a>   <span class="sc">&lt;</span>int<span class="sc">&gt;</span> <span class="er">&lt;</span>chr<span class="sc">&gt;</span>    <span class="er">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb160-4"><a href="text-analysis.html#cb160-4" tabindex="-1"></a> <span class="dv">1</span>     <span class="dv">1</span> sunday <span class="fl">0.0224</span> </span>
<span id="cb160-5"><a href="text-analysis.html#cb160-5" tabindex="-1"></a> <span class="dv">2</span>     <span class="dv">1</span> round  <span class="fl">0.0187</span> </span>
<span id="cb160-6"><a href="text-analysis.html#cb160-6" tabindex="-1"></a> <span class="dv">3</span>     <span class="dv">1</span> left   <span class="fl">0.0112</span> </span>
<span id="cb160-7"><a href="text-analysis.html#cb160-7" tabindex="-1"></a> <span class="dv">4</span>     <span class="dv">1</span> monday <span class="fl">0.0112</span> </span>
<span id="cb160-8"><a href="text-analysis.html#cb160-8" tabindex="-1"></a> <span class="dv">5</span>     <span class="dv">1</span> race   <span class="fl">0.0112</span> </span>
<span id="cb160-9"><a href="text-analysis.html#cb160-9" tabindex="-1"></a> <span class="dv">6</span>     <span class="dv">1</span> team   <span class="fl">0.0112</span> </span>
<span id="cb160-10"><a href="text-analysis.html#cb160-10" tabindex="-1"></a> <span class="dv">7</span>     <span class="dv">1</span> win    <span class="fl">0.0112</span> </span>
<span id="cb160-11"><a href="text-analysis.html#cb160-11" tabindex="-1"></a> <span class="dv">8</span>     <span class="dv">1</span> season <span class="fl">0.0112</span> </span>
<span id="cb160-12"><a href="text-analysis.html#cb160-12" tabindex="-1"></a> <span class="dv">9</span>     <span class="dv">1</span> title  <span class="fl">0.0112</span> </span>
<span id="cb160-13"><a href="text-analysis.html#cb160-13" tabindex="-1"></a><span class="dv">10</span>     <span class="dv">1</span> lewis  <span class="fl">0.00746</span></span></code></pre></div>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="text-analysis.html#cb161-1" tabindex="-1"></a>top_terms <span class="sc">%&gt;%</span></span>
<span id="cb161-2"><a href="text-analysis.html#cb161-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">term =</span> <span class="fu">reorder_within</span>(term, beta, topic)) <span class="sc">%&gt;%</span></span>
<span id="cb161-3"><a href="text-analysis.html#cb161-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(term, beta, <span class="at">fill =</span> <span class="fu">factor</span>(topic))) <span class="sc">+</span></span>
<span id="cb161-4"><a href="text-analysis.html#cb161-4" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb161-5"><a href="text-analysis.html#cb161-5" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> topic, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb161-6"><a href="text-analysis.html#cb161-6" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb161-7"><a href="text-analysis.html#cb161-7" tabindex="-1"></a>  <span class="fu">scale_x_reordered</span>() <span class="sc">+</span></span>
<span id="cb161-8"><a href="text-analysis.html#cb161-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Top-10 keywords in each topic (ESPN, latest 100)&quot;</span>,</span>
<span id="cb161-9"><a href="text-analysis.html#cb161-9" tabindex="-1"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">&quot;β (topic-word weight)&quot;</span>)</span></code></pre></div>
<p><img src="week6_plot4.png" />
What we see based on the top keywords in each topic:
• Topic 1: post-game wrap-ups / championships
• Topic 3: NFL &amp; MLB rumours
• Topic 5: Liverpool / soccer
• Topic 2: generic words (time, monday, sources) → weak
• Topic 4: catch-all rankings / lists → broad</p>
<p>How can we improve? Let’s drop obviously non-semantic tokens first, such as
words like monday, time, espn are schedule/meta terms, not content.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="text-analysis.html#cb162-1" tabindex="-1"></a>custom_stop <span class="ot">&lt;-</span> <span class="fu">c</span>(stop_words<span class="sc">$</span>word, <span class="st">&quot;monday&quot;</span>, <span class="st">&quot;tuesday&quot;</span>, <span class="st">&quot;wednesday&quot;</span>,</span>
<span id="cb162-2"><a href="text-analysis.html#cb162-2" tabindex="-1"></a>                 <span class="st">&quot;thursday&quot;</span>, <span class="st">&quot;friday&quot;</span>, <span class="st">&quot;saturday&quot;</span>, <span class="st">&quot;sunday&quot;</span>,</span>
<span id="cb162-3"><a href="text-analysis.html#cb162-3" tabindex="-1"></a>                 <span class="st">&quot;espn&quot;</span>, <span class="st">&quot;time&quot;</span>, <span class="st">&quot;sources&quot;</span>)</span>
<span id="cb162-4"><a href="text-analysis.html#cb162-4" tabindex="-1"></a>                 </span>
<span id="cb162-5"><a href="text-analysis.html#cb162-5" tabindex="-1"></a>tokens <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span> <span class="fu">filter</span>(<span class="sc">!</span>word <span class="sc">%in%</span> custom_stop)</span></code></pre></div>
<p>And let’s try a smaller topic size. let’s try 4.</p>
<p>Let’s recreate the Document-Term Matrix (articles × words).</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="text-analysis.html#cb163-1" tabindex="-1"></a>dtm <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb163-2"><a href="text-analysis.html#cb163-2" tabindex="-1"></a>  <span class="fu">count</span>(doc_id, word) <span class="sc">%&gt;%</span></span>
<span id="cb163-3"><a href="text-analysis.html#cb163-3" tabindex="-1"></a>  <span class="fu">cast_dtm</span>(<span class="at">document =</span> doc_id,</span>
<span id="cb163-4"><a href="text-analysis.html#cb163-4" tabindex="-1"></a>           <span class="at">term      =</span> word,</span>
<span id="cb163-5"><a href="text-analysis.html#cb163-5" tabindex="-1"></a>           <span class="at">value     =</span> n)</span></code></pre></div>
<p>Let’s fit a topic model with 4 topics!</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="text-analysis.html#cb164-1" tabindex="-1"></a><span class="fu">library</span>(topicmodels)</span>
<span id="cb164-2"><a href="text-analysis.html#cb164-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb164-3"><a href="text-analysis.html#cb164-3" tabindex="-1"></a>k         <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb164-4"><a href="text-analysis.html#cb164-4" tabindex="-1"></a>lda_model <span class="ot">&lt;-</span> <span class="fu">LDA</span>(dtm, <span class="at">k =</span> k, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">seed =</span> <span class="dv">42</span>))</span></code></pre></div>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="text-analysis.html#cb165-1" tabindex="-1"></a>top_terms <span class="ot">&lt;-</span> <span class="fu">tidy</span>(lda_model, <span class="at">matrix =</span> <span class="st">&quot;beta&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb165-2"><a href="text-analysis.html#cb165-2" tabindex="-1"></a>  <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span></span>
<span id="cb165-3"><a href="text-analysis.html#cb165-3" tabindex="-1"></a>  <span class="fu">slice_max</span>(beta, <span class="at">n =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span>      <span class="co"># 10 “strongest” words</span></span>
<span id="cb165-4"><a href="text-analysis.html#cb165-4" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb165-5"><a href="text-analysis.html#cb165-5" tabindex="-1"></a>  <span class="fu">arrange</span>(topic, <span class="sc">-</span>beta)</span></code></pre></div>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="text-analysis.html#cb166-1" tabindex="-1"></a>top_terms</span></code></pre></div>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="text-analysis.html#cb167-1" tabindex="-1"></a><span class="co"># A tibble: 66 × 3</span></span>
<span id="cb167-2"><a href="text-analysis.html#cb167-2" tabindex="-1"></a>   topic term         beta</span>
<span id="cb167-3"><a href="text-analysis.html#cb167-3" tabindex="-1"></a>   <span class="sc">&lt;</span>int<span class="sc">&gt;</span> <span class="er">&lt;</span>chr<span class="sc">&gt;</span>       <span class="er">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb167-4"><a href="text-analysis.html#cb167-4" tabindex="-1"></a> <span class="dv">1</span>     <span class="dv">1</span> left      <span class="fl">0.0231</span> </span>
<span id="cb167-5"><a href="text-analysis.html#cb167-5" tabindex="-1"></a> <span class="dv">2</span>     <span class="dv">1</span> top       <span class="fl">0.00990</span></span>
<span id="cb167-6"><a href="text-analysis.html#cb167-6" tabindex="-1"></a> <span class="dv">3</span>     <span class="dv">1</span> star      <span class="fl">0.00990</span></span>
<span id="cb167-7"><a href="text-analysis.html#cb167-7" tabindex="-1"></a> <span class="dv">4</span>     <span class="dv">1</span> day       <span class="fl">0.00990</span></span>
<span id="cb167-8"><a href="text-analysis.html#cb167-8" tabindex="-1"></a> <span class="dv">5</span>     <span class="dv">1</span> list      <span class="fl">0.00990</span></span>
<span id="cb167-9"><a href="text-analysis.html#cb167-9" tabindex="-1"></a> <span class="dv">6</span>     <span class="dv">1</span> lewis     <span class="fl">0.00660</span></span>
<span id="cb167-10"><a href="text-analysis.html#cb167-10" tabindex="-1"></a> <span class="dv">7</span>     <span class="dv">1</span> inning    <span class="fl">0.00660</span></span>
<span id="cb167-11"><a href="text-analysis.html#cb167-11" tabindex="-1"></a> <span class="dv">8</span>     <span class="dv">1</span> play      <span class="fl">0.00660</span></span>
<span id="cb167-12"><a href="text-analysis.html#cb167-12" tabindex="-1"></a> <span class="dv">9</span>     <span class="dv">1</span> game      <span class="fl">0.00660</span></span>
<span id="cb167-13"><a href="text-analysis.html#cb167-13" tabindex="-1"></a><span class="dv">10</span>     <span class="dv">1</span> hamstring <span class="fl">0.00660</span></span>
<span id="cb167-14"><a href="text-analysis.html#cb167-14" tabindex="-1"></a><span class="co"># ℹ 56 more rows</span></span>
<span id="cb167-15"><a href="text-analysis.html#cb167-15" tabindex="-1"></a><span class="co"># ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="text-analysis.html#cb168-1" tabindex="-1"></a>top_terms <span class="sc">%&gt;%</span></span>
<span id="cb168-2"><a href="text-analysis.html#cb168-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">term =</span> <span class="fu">reorder_within</span>(term, beta, topic)) <span class="sc">%&gt;%</span></span>
<span id="cb168-3"><a href="text-analysis.html#cb168-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(term, beta, <span class="at">fill =</span> <span class="fu">factor</span>(topic))) <span class="sc">+</span></span>
<span id="cb168-4"><a href="text-analysis.html#cb168-4" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb168-5"><a href="text-analysis.html#cb168-5" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> topic, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb168-6"><a href="text-analysis.html#cb168-6" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb168-7"><a href="text-analysis.html#cb168-7" tabindex="-1"></a>  <span class="fu">scale_x_reordered</span>() <span class="sc">+</span></span>
<span id="cb168-8"><a href="text-analysis.html#cb168-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Top-10 keywords in each topic (ESPN, latest 100)&quot;</span>,</span>
<span id="cb168-9"><a href="text-analysis.html#cb168-9" tabindex="-1"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">&quot;β (topic-word weight)&quot;</span>)</span></code></pre></div>
<p><img src="week6_plot5.png" /></p>
<p>What we observe now?</p>
<p>Topic 1 reads like a “roster moves / injury-updates” grab-bag: headlines about a player left off a squad list, someone placed on retroactive injured list, betting odds if a star “might move”. Still littered with generic tokens (top, day, list).</p>
<p>Topic 2 a broad competition &amp; tournament theme (World Cup, playoff series, round of X).</p>
<p>Topic 3 is very clear: Liverpool FC / Premier-League storylines, focused on Trent Alexander-Arnold and title talk.</p>
<p>Topic 4 feels like rankings / power-list / draft coverage; many “Top 10 Teams” or “Live Draft” style blurbs. Still noisy (live, york, espn’s).</p>
<p>Let’s now turn to topic proportions per document (γ matrix). Essentially, we measure the topic identity for each of the 100 news articles.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="text-analysis.html#cb169-1" tabindex="-1"></a>doc_topics <span class="ot">&lt;-</span> <span class="fu">tidy</span>(lda_model, <span class="at">matrix =</span> <span class="st">&quot;gamma&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="text-analysis.html#cb170-1" tabindex="-1"></a>doc_topics</span></code></pre></div>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="text-analysis.html#cb171-1" tabindex="-1"></a> <span class="co"># A tibble: 400 × 3</span></span>
<span id="cb171-2"><a href="text-analysis.html#cb171-2" tabindex="-1"></a>   document topic   gamma</span>
<span id="cb171-3"><a href="text-analysis.html#cb171-3" tabindex="-1"></a>   <span class="sc">&lt;</span>chr<span class="sc">&gt;</span>    <span class="er">&lt;</span>int<span class="sc">&gt;</span>   <span class="er">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb171-4"><a href="text-analysis.html#cb171-4" tabindex="-1"></a> <span class="dv">1</span> <span class="dv">1</span>            <span class="dv">1</span> <span class="fl">0.993</span>  </span>
<span id="cb171-5"><a href="text-analysis.html#cb171-5" tabindex="-1"></a> <span class="dv">2</span> <span class="dv">2</span>            <span class="dv">1</span> <span class="fl">0.997</span>  </span>
<span id="cb171-6"><a href="text-analysis.html#cb171-6" tabindex="-1"></a> <span class="dv">3</span> <span class="dv">3</span>            <span class="dv">1</span> <span class="fl">0.996</span>  </span>
<span id="cb171-7"><a href="text-analysis.html#cb171-7" tabindex="-1"></a> <span class="dv">4</span> <span class="dv">4</span>            <span class="dv">1</span> <span class="fl">0.996</span>  </span>
<span id="cb171-8"><a href="text-analysis.html#cb171-8" tabindex="-1"></a> <span class="dv">5</span> <span class="dv">5</span>            <span class="dv">1</span> <span class="fl">0.00157</span></span>
<span id="cb171-9"><a href="text-analysis.html#cb171-9" tabindex="-1"></a> <span class="dv">6</span> <span class="dv">6</span>            <span class="dv">1</span> <span class="fl">0.00146</span></span>
<span id="cb171-10"><a href="text-analysis.html#cb171-10" tabindex="-1"></a> <span class="dv">7</span> <span class="dv">7</span>            <span class="dv">1</span> <span class="fl">0.00170</span></span>
<span id="cb171-11"><a href="text-analysis.html#cb171-11" tabindex="-1"></a> <span class="dv">8</span> <span class="dv">8</span>            <span class="dv">1</span> <span class="fl">0.00114</span></span>
<span id="cb171-12"><a href="text-analysis.html#cb171-12" tabindex="-1"></a> <span class="dv">9</span> <span class="dv">9</span>            <span class="dv">1</span> <span class="fl">0.00108</span></span>
<span id="cb171-13"><a href="text-analysis.html#cb171-13" tabindex="-1"></a><span class="dv">10</span> <span class="dv">10</span>           <span class="dv">1</span> <span class="fl">0.00128</span></span>
<span id="cb171-14"><a href="text-analysis.html#cb171-14" tabindex="-1"></a><span class="co"># ℹ 390 more rows</span></span>
<span id="cb171-15"><a href="text-analysis.html#cb171-15" tabindex="-1"></a><span class="co"># ℹ Use `print(n = ...)` to see more rows</span></span></code></pre></div>
<p>Let’s now plot average prominence of each topic across the corpus.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="text-analysis.html#cb172-1" tabindex="-1"></a>doc_topics <span class="sc">%&gt;%</span></span>
<span id="cb172-2"><a href="text-analysis.html#cb172-2" tabindex="-1"></a>  <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span></span>
<span id="cb172-3"><a href="text-analysis.html#cb172-3" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">mean_gamma =</span> <span class="fu">mean</span>(gamma)) <span class="sc">%&gt;%</span></span>
<span id="cb172-4"><a href="text-analysis.html#cb172-4" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="fu">factor</span>(topic), mean_gamma, <span class="at">fill =</span> <span class="fu">factor</span>(topic))) <span class="sc">+</span></span>
<span id="cb172-5"><a href="text-analysis.html#cb172-5" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb172-6"><a href="text-analysis.html#cb172-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Share of attention each topic gets (all 100 stories)&quot;</span>,</span>
<span id="cb172-7"><a href="text-analysis.html#cb172-7" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Topic&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Mean γ (document-topic proportion)&quot;</span>)</span></code></pre></div>
<p><img src="week6_plot6.png" /></p>
<p>We can see that topic 4 (on draft and rankings) is most salient across the articles.</p>
<p>In this section, we see the usefulness of topic modeling and also see its weakness. First, we need to pre-specify K. That is, we must choose the number of topics in advance. In addition, high-frequency function words can dominate a topic if not carefully filtered/weighted. Finally,some learned topics are statistical artifacts (mixtures of unrelated high-probability words).</p>
</div>
<div id="word-embeddings" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Word Embeddings<a href="text-analysis.html#word-embeddings" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have encountered the concept of word embeddings multiple times in the readings. It is now the time to actually see how it works! Essentially, a word embedding instead gives every word a vector—just a short list of numbers, e.g.</p>
<p><span class="math display">\[
lion  →  [-0.11, 0.87, 0.02, …, 0.35]   \\
coward → [ 0.64, -0.57, …, -0.12]
\]</span></p>
<p>Words that appear in similar contexts (“The lion showed great courage”) will get vectors that sit near each other in this multi-dimensional space.</p>
<p>We can then:
1. measure semantic similarity (cosine distance),
3. add &amp; subtract meanings (king – man + woman ≈ queen),
3. feed the vectors into regressions.</p>
<p>Let’s see how to construct word embeddings from text!</p>
<p>We already built text_oz_filtered in the sentiment section. It is a data-frame where each row is a word (token).</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="text-analysis.html#cb173-1" tabindex="-1"></a><span class="fu">library</span>(text2vec)       <span class="co"># Framework for GloVe / word2vec in R</span></span>
<span id="cb173-2"><a href="text-analysis.html#cb173-2" tabindex="-1"></a></span>
<span id="cb173-3"><a href="text-analysis.html#cb173-3" tabindex="-1"></a>tokens <span class="ot">&lt;-</span> text_oz_filtered<span class="sc">$</span>word   <span class="co"># grab the column as a character vector</span></span>
<span id="cb173-4"><a href="text-analysis.html#cb173-4" tabindex="-1"></a><span class="fu">length</span>(tokens)                    <span class="co"># sanity-check: ~25 000 tokens</span></span></code></pre></div>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="text-analysis.html#cb174-1" tabindex="-1"></a><span class="dv">12322</span></span></code></pre></div>
<p>Now we need to decide which words are worth learning vectors for.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="text-analysis.html#cb175-1" tabindex="-1"></a>tokens_list <span class="ot">&lt;-</span> <span class="fu">list</span>(tokens)   </span>
<span id="cb175-2"><a href="text-analysis.html#cb175-2" tabindex="-1"></a>it  <span class="ot">&lt;-</span> <span class="fu">itoken</span>(tokens_list, <span class="at">progressbar =</span> <span class="cn">FALSE</span>) <span class="co"># text2vec “iterator” over tokens</span></span>
<span id="cb175-3"><a href="text-analysis.html#cb175-3" tabindex="-1"></a></span>
<span id="cb175-4"><a href="text-analysis.html#cb175-4" tabindex="-1"></a>vocab <span class="ot">&lt;-</span> <span class="fu">create_vocabulary</span>(it) <span class="sc">%&gt;%</span> <span class="fu">prune_vocabulary</span>(<span class="at">term_count_min =</span> <span class="dv">5</span>) <span class="co"># build + prune</span></span></code></pre></div>
<p>Each row of vocab now lists a word (“term”) and how many times it appeared. Low-frequency words are thrown away because the model has too little information to pin down their meaning.</p>
<p>Let’s now build a Term–Co-Occurrence Matrix (TCM). Why? GloVe does not look at documents; it looks at windows of neighbouring words.
For every pair of words, it counts how often they show up within, say, 5 words of each other.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="text-analysis.html#cb176-1" tabindex="-1"></a>vectorizer <span class="ot">&lt;-</span> <span class="fu">vocab_vectorizer</span>(vocab)     <span class="co"># tells text2vec how to convert tokens → IDs</span></span>
<span id="cb176-2"><a href="text-analysis.html#cb176-2" tabindex="-1"></a></span>
<span id="cb176-3"><a href="text-analysis.html#cb176-3" tabindex="-1"></a>tcm <span class="ot">&lt;-</span> <span class="fu">create_tcm</span>(it,</span>
<span id="cb176-4"><a href="text-analysis.html#cb176-4" tabindex="-1"></a>                  vectorizer,</span>
<span id="cb176-5"><a href="text-analysis.html#cb176-5" tabindex="-1"></a>                  <span class="at">skip_grams_window =</span> <span class="dv">5</span><span class="dt">L</span>) <span class="co"># ±5-word window around a focus term</span></span>
<span id="cb176-6"><a href="text-analysis.html#cb176-6" tabindex="-1"></a><span class="fu">dim</span>(tcm)     <span class="co"># (vocabulary size) × (vocabulary size) sparse matrix</span></span></code></pre></div>
<p>Let’s check what is inside</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="text-analysis.html#cb177-1" tabindex="-1"></a>             lion  Dorothy  heart ...</span>
<span id="cb177-2"><a href="text-analysis.html#cb177-2" tabindex="-1"></a>lion           <span class="dv">0</span>      <span class="dv">27</span>      <span class="dv">12</span></span>
<span id="cb177-3"><a href="text-analysis.html#cb177-3" tabindex="-1"></a>Dorothy       <span class="dv">27</span>       <span class="dv">0</span>      <span class="dv">15</span></span>
<span id="cb177-4"><a href="text-analysis.html#cb177-4" tabindex="-1"></a>heart         <span class="dv">12</span>      <span class="dv">15</span>       <span class="dv">0</span></span>
<span id="cb177-5"><a href="text-analysis.html#cb177-5" tabindex="-1"></a>...</span></code></pre></div>
<p>Inside the matrix, a value of 27 means “lion” appeared within five words of “Dorothy” 27 times. The matrix is sparse and stored efficiently—most pairs never co-occur.</p>
<p>Now we can run GloVe model, a popular word embedding method!</p>
<p>Parameter Intuition
rank Output dimensions. More ≈ richer detail but needs bigger data.
x_max Caps the influence of very frequent pairs; 10 is usual.
n_iter Training passes over the TCM. Watch the loss metric—stop early if it plateaus.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="text-analysis.html#cb178-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)                      <span class="co"># reproducible experiments</span></span>
<span id="cb178-2"><a href="text-analysis.html#cb178-2" tabindex="-1"></a>glove <span class="ot">&lt;-</span> GlobalVectors<span class="sc">$</span><span class="fu">new</span>(<span class="at">rank =</span> <span class="dv">50</span>,   <span class="co"># 50 dims ≈ sweet spot for small corpora</span></span>
<span id="cb178-3"><a href="text-analysis.html#cb178-3" tabindex="-1"></a>                           <span class="at">x_max =</span> <span class="dv">10</span>)  <span class="co"># how strongly to down-weight rare pairs</span></span>
<span id="cb178-4"><a href="text-analysis.html#cb178-4" tabindex="-1"></a></span>
<span id="cb178-5"><a href="text-analysis.html#cb178-5" tabindex="-1"></a>word_vectors_main <span class="ot">&lt;-</span> glove<span class="sc">$</span><span class="fu">fit_transform</span>(tcm,</span>
<span id="cb178-6"><a href="text-analysis.html#cb178-6" tabindex="-1"></a>                                         <span class="at">n_iter =</span> <span class="dv">15</span>,            <span class="co"># training epochs</span></span>
<span id="cb178-7"><a href="text-analysis.html#cb178-7" tabindex="-1"></a>                                         <span class="at">convergence_tol =</span> <span class="fl">1e-3</span>) <span class="co"># stop if improvement &lt; ε</span></span>
<span id="cb178-8"><a href="text-analysis.html#cb178-8" tabindex="-1"></a></span>
<span id="cb178-9"><a href="text-analysis.html#cb178-9" tabindex="-1"></a><span class="co"># GloVe learns two sets of vectors (main + context).  Sum them:</span></span>
<span id="cb178-10"><a href="text-analysis.html#cb178-10" tabindex="-1"></a>word_vectors <span class="ot">&lt;-</span> word_vectors_main <span class="sc">+</span> <span class="fu">t</span>(glove<span class="sc">$</span>components)</span>
<span id="cb178-11"><a href="text-analysis.html#cb178-11" tabindex="-1"></a></span>
<span id="cb178-12"><a href="text-analysis.html#cb178-12" tabindex="-1"></a><span class="fu">dim</span>(word_vectors)   <span class="co"># (vocabulary size) × 50</span></span></code></pre></div>
<p>Now let’s find nearest neighbours</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="text-analysis.html#cb179-1" tabindex="-1"></a>sim_words <span class="ot">&lt;-</span> <span class="cf">function</span>(term, <span class="at">n =</span> <span class="dv">3</span>) {</span>
<span id="cb179-2"><a href="text-analysis.html#cb179-2" tabindex="-1"></a>  sims <span class="ot">&lt;-</span> <span class="fu">sim2</span>(word_vectors,</span>
<span id="cb179-3"><a href="text-analysis.html#cb179-3" tabindex="-1"></a>               word_vectors[term, , <span class="at">drop =</span> <span class="cn">FALSE</span>],</span>
<span id="cb179-4"><a href="text-analysis.html#cb179-4" tabindex="-1"></a>               <span class="at">method =</span> <span class="st">&quot;cosine&quot;</span>, <span class="at">norm =</span> <span class="st">&quot;l2&quot;</span>)</span>
<span id="cb179-5"><a href="text-analysis.html#cb179-5" tabindex="-1"></a>  <span class="fu">sort</span>(sims[,<span class="dv">1</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>)[<span class="dv">2</span><span class="sc">:</span>(n<span class="sc">+</span><span class="dv">1</span>)]   <span class="co"># drop self-similarity</span></span>
<span id="cb179-6"><a href="text-analysis.html#cb179-6" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="text-analysis.html#cb180-1" tabindex="-1"></a><span class="fu">sim_words</span>(<span class="st">&quot;dorothy&quot;</span>)</span>
<span id="cb180-2"><a href="text-analysis.html#cb180-2" tabindex="-1"></a>scarecrow        oz   replied </span>
<span id="cb180-3"><a href="text-analysis.html#cb180-3" tabindex="-1"></a><span class="fl">0.7104297</span> <span class="fl">0.6610949</span> <span class="fl">0.6609231</span> </span></code></pre></div>
<p>Key take-aways
1. Word embeddings let you turn raw text into numeric features that “know” something about meaning.
2. Even a tiny corpus like The Wonderful Wizard of Oz gives vectors that make intuitive sense.
3. Once vectors exist, you can visualise them, cluster them, feed them into any machine-learning or statistical model—exactly as you would with height, age, or income.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="collecting-data-online.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yuzesui97/soc10_2025spring/edit/main/07-Text_Analysis.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/yuzesui97/soc10_2025spring/blob/main/07-Text_Analysis.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
