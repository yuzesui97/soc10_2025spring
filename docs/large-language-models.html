<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Week 8 Large Language Models | Stanford Spring 2025 Intro to Computational Social Science</title>
  <meta name="description" content="Week 8 Large Language Models | Stanford Spring 2025 Intro to Computational Social Science" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Week 8 Large Language Models | Stanford Spring 2025 Intro to Computational Social Science" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Week 8 Large Language Models | Stanford Spring 2025 Intro to Computational Social Science" />
  
  
  

<meta name="author" content="Yuze Sui" />


<meta name="date" content="2025-03-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="machine-learning-supervised-learning.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro_Comp_Social_Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="1" data-path="intro-to-r.html"><a href="intro-to-r.html"><i class="fa fa-check"></i><b>1</b> Intro to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro-to-r.html"><a href="intro-to-r.html#r-basics"><i class="fa fa-check"></i><b>1.1</b> R Basics</a></li>
<li class="chapter" data-level="1.2" data-path="intro-to-r.html"><a href="intro-to-r.html#vectors"><i class="fa fa-check"></i><b>1.2</b> Vectors</a></li>
<li class="chapter" data-level="1.3" data-path="intro-to-r.html"><a href="intro-to-r.html#loading-packages"><i class="fa fa-check"></i><b>1.3</b> Loading Packages</a></li>
<li class="chapter" data-level="1.4" data-path="intro-to-r.html"><a href="intro-to-r.html#exploring-and-visualizing-data"><i class="fa fa-check"></i><b>1.4</b> Exploring and Visualizing Data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html"><i class="fa fa-check"></i><b>2</b> Surveys and Survey Experiments with Qualtrics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#creating-a-qualtrics-account"><i class="fa fa-check"></i><b>2.2</b> Creating a Qualtrics account</a></li>
<li class="chapter" data-level="2.3" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#survey-options"><i class="fa fa-check"></i><b>2.3</b> Survey options</a></li>
<li class="chapter" data-level="2.4" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#a-quick-survey-experiment"><i class="fa fa-check"></i><b>2.4</b> A quick survey experiment</a></li>
<li class="chapter" data-level="2.5" data-path="surveys-and-survey-experiments-with-qualtrics.html"><a href="surveys-and-survey-experiments-with-qualtrics.html#publish-it"><i class="fa fa-check"></i><b>2.5</b> Publish it!</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression-and-classification.html"><a href="regression-and-classification.html"><i class="fa fa-check"></i><b>3</b> Regression and Classification</a>
<ul>
<li class="chapter" data-level="3.1" data-path="regression-and-classification.html"><a href="regression-and-classification.html#linear-regression"><i class="fa fa-check"></i><b>3.1</b> Linear Regression</a></li>
<li class="chapter" data-level="3.2" data-path="regression-and-classification.html"><a href="regression-and-classification.html#how-linear-regression-works"><i class="fa fa-check"></i><b>3.2</b> How linear regression works</a></li>
<li class="chapter" data-level="3.3" data-path="regression-and-classification.html"><a href="regression-and-classification.html#linear-regression-using-the-lm-function"><i class="fa fa-check"></i><b>3.3</b> Linear regression using the lm function</a></li>
<li class="chapter" data-level="3.4" data-path="regression-and-classification.html"><a href="regression-and-classification.html#multiple-regression"><i class="fa fa-check"></i><b>3.4</b> Multiple Regression</a></li>
<li class="chapter" data-level="3.5" data-path="regression-and-classification.html"><a href="regression-and-classification.html#linear-regression-prediction"><i class="fa fa-check"></i><b>3.5</b> Linear Regression Prediction</a></li>
<li class="chapter" data-level="3.6" data-path="regression-and-classification.html"><a href="regression-and-classification.html#classification-logistic-regression"><i class="fa fa-check"></i><b>3.6</b> Classification (Logistic Regression)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="social-network-analysis.html"><a href="social-network-analysis.html"><i class="fa fa-check"></i><b>4</b> Social Network Analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#understanding-network-data-structures-in-r"><i class="fa fa-check"></i><b>4.1</b> Understanding network data structures in R</a></li>
<li class="chapter" data-level="4.2" data-path="social-network-analysis.html"><a href="social-network-analysis.html#visualizing-network-data-in-r"><i class="fa fa-check"></i><b>4.2</b> Visualizing network data in R</a></li>
<li class="chapter" data-level="4.3" data-path="social-network-analysis.html"><a href="social-network-analysis.html#key-network-measures"><i class="fa fa-check"></i><b>4.3</b> Key network measures</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#degree-how-many-friends-do-i-have"><i class="fa fa-check"></i><b>4.3.1</b> Degree (“How many friends do I have?”)</a></li>
<li class="chapter" data-level="4.3.2" data-path="social-network-analysis.html"><a href="social-network-analysis.html#weighted-degree-strength"><i class="fa fa-check"></i><b>4.3.2</b> Weighted degree (strength)</a></li>
<li class="chapter" data-level="4.3.3" data-path="social-network-analysis.html"><a href="social-network-analysis.html#global-clustering-coefficient-gcc"><i class="fa fa-check"></i><b>4.3.3</b> Global Clustering Coefficient (GCC)</a></li>
<li class="chapter" data-level="4.3.4" data-path="social-network-analysis.html"><a href="social-network-analysis.html#average-path-length-apl"><i class="fa fa-check"></i><b>4.3.4</b> Average path length (APL)</a></li>
<li class="chapter" data-level="4.3.5" data-path="social-network-analysis.html"><a href="social-network-analysis.html#assortativity"><i class="fa fa-check"></i><b>4.3.5</b> Assortativity</a></li>
<li class="chapter" data-level="4.3.6" data-path="social-network-analysis.html"><a href="social-network-analysis.html#betweenness-centrality"><i class="fa fa-check"></i><b>4.3.6</b> Betweenness centrality</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="social-network-analysis.html"><a href="social-network-analysis.html#visualizing-key-measures"><i class="fa fa-check"></i><b>4.4</b> Visualizing Key Measures</a></li>
<li class="chapter" data-level="4.5" data-path="social-network-analysis.html"><a href="social-network-analysis.html#benchmark-our-empirical-network"><i class="fa fa-check"></i><b>4.5</b> Benchmark our empirical network</a></li>
<li class="chapter" data-level="4.6" data-path="social-network-analysis.html"><a href="social-network-analysis.html#find-local-clusterscommunities"><i class="fa fa-check"></i><b>4.6</b> Find local clusters/communities</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#other-resources"><i class="fa fa-check"></i><b>4.6.1</b> Other Resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="collecting-data-online.html"><a href="collecting-data-online.html"><i class="fa fa-check"></i><b>5</b> Collecting Data Online</a>
<ul>
<li class="chapter" data-level="5.1" data-path="collecting-data-online.html"><a href="collecting-data-online.html#scraping-the-web"><i class="fa fa-check"></i><b>5.1</b> Scraping the web</a></li>
<li class="chapter" data-level="5.2" data-path="collecting-data-online.html"><a href="collecting-data-online.html#google-news-api"><i class="fa fa-check"></i><b>5.2</b> Google News API</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="collecting-data-online.html"><a href="collecting-data-online.html#prerequistes"><i class="fa fa-check"></i><b>5.2.1</b> Prerequistes</a></li>
<li class="chapter" data-level="5.2.2" data-path="collecting-data-online.html"><a href="collecting-data-online.html#get-started"><i class="fa fa-check"></i><b>5.2.2</b> Get started</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="text-analysis.html"><a href="text-analysis.html"><i class="fa fa-check"></i><b>6</b> Text Analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="text-analysis.html"><a href="text-analysis.html#sentiment-analysis"><i class="fa fa-check"></i><b>6.1</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="6.2" data-path="text-analysis.html"><a href="text-analysis.html#topic-modeling"><i class="fa fa-check"></i><b>6.2</b> Topic Modeling</a></li>
<li class="chapter" data-level="6.3" data-path="text-analysis.html"><a href="text-analysis.html#word-embeddings"><i class="fa fa-check"></i><b>6.3</b> Word Embeddings</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="machine-learning-supervised-learning.html"><a href="machine-learning-supervised-learning.html"><i class="fa fa-check"></i><b>7</b> Machine Learning (Supervised Learning)</a>
<ul>
<li class="chapter" data-level="7.1" data-path="machine-learning-supervised-learning.html"><a href="machine-learning-supervised-learning.html#training-vs.-test-data-why-split"><i class="fa fa-check"></i><b>7.1</b> Training vs. Test Data: Why Split?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="machine-learning-supervised-learning.html"><a href="machine-learning-supervised-learning.html#splitting-the-gss-2018-data"><i class="fa fa-check"></i><b>7.1.1</b> Splitting the GSS 2018 Data</a></li>
<li class="chapter" data-level="7.1.2" data-path="machine-learning-supervised-learning.html"><a href="machine-learning-supervised-learning.html#linear-regression-with-training-and-test-data"><i class="fa fa-check"></i><b>7.1.2</b> Linear Regression with Training and Test Data</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="machine-learning-supervised-learning.html"><a href="machine-learning-supervised-learning.html#decision-trees-for-regression"><i class="fa fa-check"></i><b>7.2</b> Decision Trees for Regression</a></li>
<li class="chapter" data-level="7.3" data-path="machine-learning-supervised-learning.html"><a href="machine-learning-supervised-learning.html#random-forests"><i class="fa fa-check"></i><b>7.3</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="large-language-models.html"><a href="large-language-models.html"><i class="fa fa-check"></i><b>8</b> Large Language Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="large-language-models.html"><a href="large-language-models.html#tidychatmodels-package"><i class="fa fa-check"></i><b>8.1</b> tidychatmodels Package</a></li>
<li class="chapter" data-level="8.2" data-path="large-language-models.html"><a href="large-language-models.html#llm-as-synthetic-respondents-for-social-survey-set-up"><i class="fa fa-check"></i><b>8.2</b> LLM as “Synthetic Respondents” for Social Survey: Set-up</a></li>
<li class="chapter" data-level="8.3" data-path="large-language-models.html"><a href="large-language-models.html#llm-as-synthetic-respondents-for-social-survey-query"><i class="fa fa-check"></i><b>8.3</b> LLM as “Synthetic Respondents” for Social Survey: Query</a></li>
<li class="chapter" data-level="8.4" data-path="large-language-models.html"><a href="large-language-models.html#other-use-cases-of-llm-apis-in-computatinal-social-science"><i class="fa fa-check"></i><b>8.4</b> Other Use Cases of LLM APIs in Computatinal Social Science</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stanford Spring 2025 Intro to Computational Social Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="large-language-models" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Week 8</span> Large Language Models<a href="large-language-models.html#large-language-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This tutorial provides a hands-on way to see how large-language-model (LLM) APIs can be integrated into an R research workflow for computational social science. Using the 2018 General Social Survey, we first review tidy data handling, then prompt Mistral AI to act as “synthetic respondents” whose age, sex, race, income, and education match each sampled case.</p>
<p>By contrasting the model’s predicted 2012 presidential vote with the survey’s actual vote distribution and visualising the differences, students learn three key lessons: (1) how to call and parameterize an LLM from R with the {tidychatmodels} grammar; (2) how prompt wording and sampling settings affect generated outputs; and (3) why synthetic text should be interpreted cautiously when compared to real human behavior.</p>
<div id="tidychatmodels-package" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> tidychatmodels Package<a href="large-language-models.html#tidychatmodels-package" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this tutorial, we will use the R package “tidychatmodels”, a recently developed R package by Albert Rapp for LLM API calls, to explore how to integrate LLMs into computational social science research. I also recommend you to read the online documentation for tidychatmodels: <a href="https://albert-rapp.de/posts/20_tidychatmodels/20_tidychatmodels" class="uri">https://albert-rapp.de/posts/20_tidychatmodels/20_tidychatmodels</a></p>
<pre><code>library(devtools)
devtools::install_github(&quot;AlbertRapp/tidychatmodels&quot;)
library(tidychatmodels)</code></pre>
<p>We also need to following packages for today’s tutorial</p>
<pre><code>library(haven)
library(tidyverse)
library(glue)
library(scales)
library(pins)</code></pre>
</div>
<div id="llm-as-synthetic-respondents-for-social-survey-set-up" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> LLM as “Synthetic Respondents” for Social Survey: Set-up<a href="large-language-models.html#llm-as-synthetic-respondents-for-social-survey-set-up" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this tutorial, I want to introduce how to interact with LLM with R and how to use LLM to serve as synthetic respondents for social science surveys.</p>
<p>Let’s imagine instead of collecting responses from real humans, we conduct General Social Survey (GSS) on LLM. We can then compare the synthetic responses with the actual human responses. Specifically, I use the 2018 GSS results as the reference.</p>
<p>Let’s first load the 2018 GSS data. Specifically, I am interested in generating sythetic responses for presidential voting preference in the 2012 Prsidential election.</p>
<p>Let’s keeps only the columns we need for this demonstration:</p>
<p>age – respondent’s age in years (continuous).
sex – recorded gender (male/female).
race – self-identified race (white/black/other in 2018).
realrinc – real annual family income in 2018 dollars (numeric).
educ – years of schooling completed (0–20).
pres12 – presidential vote in the 2012 election (Obama, Romney, Other, Didn’t vote).</p>
<p>These variables give the LLM enough demographic context to generate a plausible vote while keeping the prompt short.</p>
<pre><code>gss2018 &lt;- read_dta(&quot;GSS2018.dta&quot;) %&gt;%
  select(age, sex, race, realinc, educ, pres12) </code></pre>
<p>Let’s further clean the data.</p>
<pre><code>gss2018$age &lt;- as.numeric(gss2018$age)
gss2018$realinc &lt;- as.numeric(gss2018$realinc)
gss2018$educ &lt;- as.numeric(gss2018$educ)
gss2018$pres12 &lt;- as.character(gss2018$pres12)
gss2018$sex &lt;- as.character(gss2018$sex)
gss2018$race &lt;- as.character(gss2018$race)

gss2018 &lt;- gss2018 %&gt;%
  filter(!is.na(pres12)) %&gt;%
  filter(!is.na(realinc)) %&gt;%
  filter(age &gt; 26)</code></pre>
<p>Let’s see the actual voting pattern in the survey</p>
<pre><code>vote_dist &lt;- gss2018 %&gt;%                     
  count(pres12) %&gt;%                            
  mutate(pct = n / sum(n)) 
print(vote_dist)</code></pre>
<p>1 corresponds to Obama
2 corresponds to Romney
3 corresponds to Other
4 corresponds to Did not vote</p>
<pre><code>print(vote_dist)
# A tibble: 4 × 3
  pres12     n     pct
  &lt;fct&gt;  &lt;int&gt;   &lt;dbl&gt;
1 1        850 0.647  
2 2        439 0.334  
3 3         18 0.0137 
4 4          7 0.00533</code></pre>
<p>Let’s code numueric values with actual readable choice categories:</p>
<pre><code>gss2018$pres12[gss2018$pres12==&quot;1&quot;] &lt;-&quot;Obama&quot;
gss2018$pres12[gss2018$pres12==&quot;2&quot;] &lt;-&quot;Romney&quot;
gss2018$pres12[gss2018$pres12==&quot;3&quot;] &lt;-&quot;Other&quot;
gss2018$pres12[gss2018$pres12==&quot;4&quot;] &lt;-&quot;Did not vote&quot;

gss2018$sex[gss2018$sex==&quot;1&quot;] &lt;-&quot;Male&quot;
gss2018$sex[gss2018$sex==&quot;2&quot;] &lt;-&quot;Female&quot;

gss2018$race[gss2018$race==&quot;1&quot;] &lt;-&quot;White&quot;
gss2018$race[gss2018$race==&quot;2&quot;] &lt;-&quot;Black&quot;
gss2018$race[gss2018$race==&quot;3&quot;] &lt;-&quot;Non-White and Non-Black&quot;</code></pre>
<p>Next is to get sythetic responses from LLM. The first step is creating a prompt (i.e., an instruction) for the LLM. Through prompting, we force the LLM to imagine itself to be a person with certain demographic background:</p>
<pre><code>make_prompt &lt;- function(age, sex, race, income, educ) {
  glue(&quot;Imagine you are a {age}-year-old {race} {sex} as in 2018. &quot;,
       &quot;You earn ${comma(income, accuracy = 1)} per year as in 2018&quot;,
       &quot;and completed {educ} years of schooling as in 2018. &quot;,
       &quot;Who did you vote for in the 2012 US presidential election? &quot;,
       &quot;Reply **with exactly one** of: Obama, Romney, Other, Did_not_vote.&quot;, 
       &quot;Just return choices from the above four options. No extra word or setence in your response is allowed.&quot;)
}</code></pre>
<p>We are now ready to interact with LLMs via API (recall we have encoutered the concept of API in the week for text analysis). We could use ChatGPT models (like ChatGPT 4o) but ChatGPT models are not free via API call. Instead, we use a free LLM provided by Mistral AI for this tutorial. You can set up an API key via console.mistral.ai.</p>
<pre><code>Sys.setenv(MISTRAL_KEY = &quot;TYPE YOUR API KEY HERE!&quot;)

mistral_chat &lt;- create_chat(&#39;mistral&#39;, Sys.getenv(&quot;MISTRAL_KEY&quot;)) %&gt;%
  add_model(&#39;mistral-small-latest&#39;) %&gt;%
  add_params(temperature = 0.2)   # control for randomness</code></pre>
<p>I also paste the code for initiating ChatGPT models here fore reference.</p>
<pre><code># ---- optional OpenAI branch 
openai_chat &lt;- create_chat(&quot;openai&quot;, Sys.getenv(&quot;OAI_KEY&quot;)) %&gt;%
                 add_model(&quot;gpt-4o&quot;) %&gt;%
                 add_params(temperature = 0.3)
}</code></pre>
</div>
<div id="llm-as-synthetic-respondents-for-social-survey-query" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> LLM as “Synthetic Respondents” for Social Survey: Query<a href="large-language-models.html#llm-as-synthetic-respondents-for-social-survey-query" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can now query the LLM! Let’s generate 500 responses from LLM. Let’s first sample 500 real age, sex, race, realinc, and educ combinations from the 2018 GSS data to generate the prompt.</p>
<pre><code>set.seed(42)
n_demo  &lt;- 500
sim_in  &lt;- gss2018 %&gt;% slice_sample(n = n_demo) %&gt;%
           mutate(prompt = pmap_chr(list(age, sex, race,
                                         realinc, educ), make_prompt))</code></pre>
<p>We can check the output of sim_in, which include the 500 sampled real age, sex, race, realinc, and educ combinations and the associated prompt for LLM to respond.</p>
<pre><code>head(sim_in)</code></pre>
<pre><code># A tibble: 6 × 7
    age sex    race  realinc  educ pres12 prompt                  
  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                   
1    46 Male   White  72640     16 Obama  Imagine you are a 46-ye…
2    66 Male   White  30645     20 Obama  Imagine you are a 66-ye…
3    65 Male   White   8512.     8 Obama  Imagine you are a 65-ye…
4    61 Female White  54480     20 Obama  Imagine you are a 61-ye…
5    33 Male   White    227     12 Obama  Imagine you are a 33-ye…
6    28 Male   White  24970     18 Obama  Imagine you are a 28-ye…</code></pre>
<p>Now let’s query the LLM using the customized ask function and store the answer.</p>
<pre><code>library(purrr)
library(pins)
library(stringr)

# ---- helper that returns ONE cleaned token
## out &lt;- … – sends the prompt to the model and gets back the full chat history as a character vector.
## out[length(out)] – keeps only the last element (the assistant’s reply).
-----------------------------
ask_raw &lt;- function(chat, prompt) {
  log_vec &lt;- chat %&gt;%
    add_message(prompt) %&gt;%
    perform_chat() %&gt;%
    extract_chat()              # character vector, one element per turn

  # 1. pick the assistant line (the one that begins with &#39;Assistant:&#39;)
  assistant_line &lt;- log_vec[str_detect(log_vec, &quot;^Assistant:&quot;)]

  # if for some reason that pattern isn&#39;t found, fall back to the last turn
  if (length(assistant_line) == 0) assistant_line &lt;- tail(log_vec, 1)

  # 2. remove the &#39;Assistant:&#39; tag, trim white-space
  clean &lt;- str_trim(str_remove(assistant_line, &quot;^Assistant:\\s*&quot;))

  # 3. collapse to length-1 string (in case of accidental line breaks)
  paste(clean, collapse = &quot; &quot;)
}</code></pre>
<pre><code># ---- wrap it with a 1-request-per-sec rate limiter
## safely() → converts run-time errors (e.g., HTTP 429) into an NA result instead of stopping the loop.
## slowly() → enforces one call per second (rate_delay(1)), satisfying Mistral’s free-tier quota.
## ask_thrott is the error-tolerant, rate-limited wrapper we’ll call inside the loop.
---------------------
ask_safe   &lt;- safely(ask_raw, otherwise = NA_character_)
ask_thrott &lt;- slowly(ask_safe, rate = rate_delay(1))   # 1 request / second</code></pre>
<pre><code># ---- prepare pin board and existing progress
## Creates a temporary pins “board”. Everything we cache will live here under the name mistral_sim.
--------------------------
board    &lt;- board_temp()        # temp folder inside this R session
pin_name &lt;- &quot;mistral_raw&quot;

if (pin_exists(board, pin_name)) {
  sim_out  &lt;- pin_read(board, pin_name)       # resume
  done_ids &lt;- sim_out$row_id
} else {
  sim_out  &lt;- tibble()                        # start fresh
  done_ids &lt;- integer(0)
}</code></pre>
<pre><code># ---- iterate row-by-row with progress bar
## Adds a row_id column so we can track per-row completion, then builds a progress bar for user feedback.
-----------------------------
sim_in2 &lt;- sim_in %&gt;% mutate(row_id = row_number())      # keep row id
todo    &lt;- sim_in2 %&gt;% filter(!row_id %in% done_ids)     # rows still to query

pb &lt;- progress::progress_bar$new(
  format = &quot;  querying [:bar] :percent eta: :eta&quot;,
  total  = nrow(todo)
)</code></pre>
<pre><code># Loop body: queries the LLM at a safe rate, appends the new vote (or NA on error) to sim_out, and advances the progress bar.
-----------------------------
for (i in seq_len(nrow(todo))) {
  row  &lt;- todo[i, ]
  ans  &lt;- ask_thrott(mistral_chat, row$prompt)  # throttled API call
  raw  &lt;- ans$result                            # NA if error

  sim_out &lt;- bind_rows(sim_out,
                       row %&gt;% mutate(llm_raw = raw))

  pb$tick()

  # write/update pin every 25 rows (or on final row)
  if (i %% 25 == 0 || i == nrow(todo)) {
    pin_write(board, sim_out, pin_name, type = &quot;rds&quot;)
  }
}</code></pre>
<p>Let’s see what we got for the llm responses:</p>
<pre><code>head(sim_out$llm_raw)
[1] &quot;assistant Romney&quot;       &quot;assistant Romney&quot;       &quot;assistant Did_not_vote&quot;
[4] &quot;assistant Did_not_vote&quot; &quot;assistant Did_not_vote&quot; &quot;assistant Did_not_vote&quot;</code></pre>
<p>Apparently, we need to further clean up the raw responses:</p>
<pre><code>sim_out &lt;- sim_out %&gt;%
  mutate(
    # 1. strip the role tag and whitespace
    llm_vote = str_remove(llm_raw, &quot;^assistant\\s*&quot;) |&gt; str_trim(),
    
    # 2. standardise to four canonical values (anything else → NA)
    llm_vote = case_when(
      str_detect(llm_vote, regex(&quot;^Obama$&quot;,          ignore_case = TRUE)) ~ &quot;Obama&quot;,
      str_detect(llm_vote, regex(&quot;^Romney$&quot;,         ignore_case = TRUE)) ~ &quot;Romney&quot;,
      str_detect(llm_vote, regex(&quot;^Other$&quot;,          ignore_case = TRUE)) ~ &quot;Other&quot;,
      str_detect(llm_vote, regex(&quot;^Did[_ ]?not[_ ]?vote$&quot;, ignore_case = TRUE)) ~ &quot;Did not vote&quot;,
      TRUE ~ NA_character_
    )
  )</code></pre>
<p>Let’s compare the actual response distribution with the sythetic ones!</p>
<pre><code>real &lt;- sim_out %&gt;% count(pres12, name = &quot;real_n&quot;) %&gt;%
        mutate(real_pct = real_n / sum(real_n))

# ── 1. Compute synthetic distribution in numeric form ────────────────
synthetic &lt;- sim_out %&gt;%
  filter(!is.na(llm_vote)) %&gt;%                 # drop invalid / NA answers
  count(pres12 = llm_vote, name = &quot;llm_n&quot;) %&gt;% # same column name as real
  mutate(llm_pct = llm_n / sum(llm_n))

# ── 2. Join &amp; reshape for plotting ───────────────────────────────────
plot_df &lt;- full_join(real, synthetic, by = &quot;pres12&quot;) %&gt;%         # combine
  pivot_longer(cols = c(real_pct, llm_pct),                      # wide → long
               names_to  = &quot;source&quot;,
               values_to = &quot;pct&quot;) %&gt;%
  mutate(source = recode(source,
                         real_pct = &quot;Actual GSS&quot;,
                         llm_pct  = &quot;LLM (Mistral)&quot;))

# ── 3. Side-by-side bar chart ────────────────────────────────────────
ggplot(plot_df, aes(x = pres12, y = pct, fill = source)) +
  geom_col(position = &quot;dodge&quot;) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_fill_manual(values = c(&quot;Actual GSS&quot; = &quot;steelblue&quot;,
                               &quot;LLM (Mistral)&quot; = &quot;darkorange&quot;)) +
  labs(title = &quot;2012 Presidential Vote: Actual vs. Synthetic Respondents&quot;,
       x = NULL, y = &quot;Share of respondents&quot;,
       fill = NULL) +
  theme_minimal(base_size = 13)</code></pre>
<p><img src="week8_plot1.png" />
We can compare the alignment using different LLMs.</p>
</div>
<div id="other-use-cases-of-llm-apis-in-computatinal-social-science" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Other Use Cases of LLM APIs in Computatinal Social Science<a href="large-language-models.html#other-use-cases-of-llm-apis-in-computatinal-social-science" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>We can ask LLMs to evaluate/label the sentiment of different text/documents</li>
<li>Coding open-ended survey answers: Instead of hiring dozens of coders to transform free-text responses into numeric categories (e.g., “occupation”, “policy preference”), an LLM can propose a code and a confidence score; researchers then audit a stratified subsample for reliability.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="machine-learning-supervised-learning.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yuzesui97/soc10_2025spring/edit/main/09-Large_Language_Models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/yuzesui97/soc10_2025spring/blob/main/09-Large_Language_Models.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
